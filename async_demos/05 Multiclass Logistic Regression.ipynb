{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "imcNmFXhPdCh"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-16 18:50:34.992641: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-06-16 18:50:34.993500: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-06-16 18:50:35.012273: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-06-16 18:50:35.107917: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-16 18:50:36.404908: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# Import our standard libraries.\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns  # for nicer plots\n",
    "sns.set(style='darkgrid')  # default style\n",
    "import tensorflow as tf\n",
    "np.set_printoptions(precision=3, suppress=True)  # improve float readability\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P4mROCY5wAX4"
   },
   "source": [
    "## Iris Classification\n",
    "\n",
    "We will train a classifier to predict 3 iris varieties from 4 features of each flower. Note: we are not doing image classification here!\n",
    "\n",
    "![An image](https://drive.google.com/uc?id=12gf4Q0K45gvw-tUDt_sWsbAl-f0klhib)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "37XEUjK4ulzp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (150, 4)\n",
      "Y shape: (150,)\n",
      "feature names: ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "class names: ['setosa' 'versicolor' 'virginica']\n",
      "First example: [5.1 3.5 1.4 0.2] 0\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "Y = iris.target\n",
    "feature_names = iris.feature_names\n",
    "class_names = iris.target_names\n",
    "\n",
    "print('X shape:', X.shape)\n",
    "print('Y shape:', Y.shape)\n",
    "print('feature names:', feature_names)\n",
    "print('class names:', class_names)\n",
    "print('First example:', X[0], Y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O3GC13Sf219q"
   },
   "source": [
    "## Data Processing\n",
    "\n",
    "* Shuffle\n",
    "* Split into train/test\n",
    "* Apply mean and variance normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "-sa_lrwU1oiT"
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "shuffled_indices = np.random.permutation(range(len(Y)))\n",
    "X = X[shuffled_indices]\n",
    "Y = Y[shuffled_indices]\n",
    "\n",
    "X_train = X[0:100]\n",
    "Y_train = Y[0:100]\n",
    "X_test = X[100:150]\n",
    "Y_test = Y[100:150]\n",
    "\n",
    "X_train_means = np.mean(X_train, axis=0)\n",
    "X_train_stds = np.std(X_train, axis=0)\n",
    "X_train = (X_train - X_train_means) / X_train_stds\n",
    "X_test = (X_test - X_train_means)/ X_train_stds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4jIgCYbiVAz3"
   },
   "source": [
    "## Sparse vs Dense Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "8bcduWsAbCRl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 3)\n",
      "[[0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# Convert Y from sparse to dense if needed\n",
    "# one-hot [0, 0, 1] -> 2\n",
    "# one-hot [0, 1, 0] -> 1\n",
    "# one-hot [1, 0, 0] -> 0\n",
    "Y_train_dense = tf.keras.utils.to_categorical(Y_train)\n",
    "print(Y_train_dense.shape)\n",
    "print(Y_train_dense[:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FS7LIrIlVd2E"
   },
   "source": [
    "## Softmax Regression Functional Form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_tdGfEoDovBm"
   },
   "source": [
    "We will use *softmax regression*, which extends *logistic regression* to the multiclass setting. Our model will make predictions for input examples $X$ by:\n",
    "\n",
    "\\begin{align}\n",
    "\\hat{Y} = h_W(X) = \\phi(XW^T) =\n",
    "\\phi\\begin{pmatrix}\n",
    "x_{0,0} & x_{0,1} & x_{0,2} & x_{0,3} \\\\\n",
    "x_{1,0} & x_{1,1} & x_{1,2} & x_{1,3} \\\\\n",
    "\\vdots & \\vdots & \\vdots & \\vdots \\\\\n",
    "x_{m-1,0} & x_{m-1,1} & x_{m-1,2} & x_{m-1,3} \\\\\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "w_{0,0} & w_{1,0} & w_{2,0} \\\\\n",
    "w_{0,1} & w_{1,1} & w_{2,1} \\\\\n",
    "w_{0,2} & w_{1,2} & w_{2,2} \\\\\n",
    "w_{0,3} & w_{1,3} & w_{2,3} \\\\\n",
    "\\end{pmatrix}\n",
    "\\end{align}\n",
    "\n",
    "A few notes about this computation:\n",
    "\n",
    "* Our X has shape (100 x 4): 100 examples and 4 features\n",
    "* Our W has shape (3 x 4): 3 classes and 4 features. The indices above are reversed because we've taken the transpose of W: the first column of $W^T$ contains the weights for the first class.\n",
    "* The result will have shape (100 x 3): 3 probabilities corresponding to the 3 classes for each of the 100 examples.\n",
    "* $\\phi$ is the softmax function: $\\frac{e^{z_i}}{\\sum_j e^{z_j}}$. It is applied to the rows of $XW^T$.\n",
    "\n",
    "More detailed background [here](http://deeplearning.stanford.edu/tutorial/supervised/SoftmaxRegression/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nAoIx-nkXhD-"
   },
   "source": [
    "## Softmax Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Hpah13BcCVXo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.09  0.245 0.665]\n",
      " [0.016 0.117 0.867]]\n"
     ]
    }
   ],
   "source": [
    "# Remember the sigmoid function.\n",
    "def sigmoid(z):\n",
    "  return 1 / (1 + np.exp(-z))\n",
    "\n",
    "# Our softmax function will normalize over the rows of the input matrix.\n",
    "def softmax(z):\n",
    "  \"\"\"z has shape (m, n): examples, classes\"\"\"\n",
    "  (m, n) = z.shape\n",
    "\n",
    "  # First exponentiate each value\n",
    "  exps = np.exp(z)\n",
    "\n",
    "  # Get the sum of each row and normalize\n",
    "  row_sums = np.sum(exps, axis=1)\n",
    "  for i in range(m):\n",
    "    exps[i,:] /= row_sums[i]\n",
    "  \n",
    "  # Fancy/tricky way to do row-wise sums in numpy:\n",
    "  # return np.divide(exps.T, np.sum(exps, axis=1)).T\n",
    "\n",
    "  return exps\n",
    "\n",
    "# Try an example.\n",
    "v = np.array([[1,2,3],\n",
    "              [0,2,4]])\n",
    "print(softmax(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KLh6VWUfGm7_"
   },
   "source": [
    "## Making Predictions\n",
    "\n",
    "Now, given some initial parameter values (below), compute the model's initial predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "pGg1Ll4I4jR6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions:\n",
      " [[0.333 0.333 0.333]\n",
      " [0.333 0.333 0.333]\n",
      " [0.333 0.333 0.333]\n",
      " [0.333 0.333 0.333]\n",
      " [0.333 0.333 0.333]\n",
      " [0.333 0.333 0.333]]\n",
      "label predictions:\n",
      " [0 0 0 0 0 0]\n",
      "true labels:\n",
      " [2 1 0 2 0 2]\n"
     ]
    }
   ],
   "source": [
    "# Initial parameter values.\n",
    "# W = np.random.uniform(size=(3,4))\n",
    "W = np.ones((3,4))\n",
    "\n",
    "# Compute predictions.\n",
    "preds = softmax(np.dot(X_train, W.T))\n",
    "print('predictions:\\n', preds[:6])\n",
    "print('label predictions:\\n', np.argmax(preds, axis=1)[:6])\n",
    "print('true labels:\\n', Y_train[:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZIbpXB4ZHPvO"
   },
   "source": [
    "## Cross-Entropy Loss\n",
    "\n",
    "We'll use the general form of *cross-entropy* loss:\n",
    "\n",
    "\\begin{align}\n",
    "CrossEntropyLoss = \\frac{1}{m} \\sum_i \\sum_j -y_j\\log(\\hat{y_j})\n",
    "\\end{align}\n",
    "\n",
    "In this formula:\n",
    "\n",
    "* $j$ indexes the classes (in our case [0,1,2]) and each $y$ has a dense representation like [0,0,1] which indicates class 2.\n",
    "* *i* indexes over training examples, so we're computing an average loss (as usual)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "lWxpr2OogN70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0986122886681093\n"
     ]
    }
   ],
   "source": [
    "def ce_loss(preds, Y):\n",
    "  \"\"\"\n",
    "    preds are (m,n) m = number of examples, n = number of classes\n",
    "    Y is (m,) -- array of sparse labels \n",
    "    preds[0] = [.1, .1, .8] Y[0] = 2 Y_dense[0] = [0, 0, 1]\n",
    "  \"\"\"\n",
    "  # Get the number of examples\n",
    "  m = Y.shape[0]\n",
    "\n",
    "  # Compute the first sum, the cross-entropy for each example, using\n",
    "  # the rows of the predictions and corresponding labels.\n",
    "  # Note that we need the dense (one-hot) labels.\n",
    "  Y_dense = tf.keras.utils.to_categorical(Y)\n",
    "  # [.1, .1, .8] [0, 0, 1] -> [0, 0, -1*log(.8)] -> -1*log(.8)\n",
    "  cross_entropy_values = - np.sum(Y_dense * np.log(preds), axis=1)\n",
    "\n",
    "  # Here's a more efficient but tricky way to do this:\n",
    "  # cross_entropy_values = -np.log(preds[range(m), Y])\n",
    "\n",
    "  # Sum the per-example cross-entropy values.\n",
    "  loss = np.sum(cross_entropy_values) / m\n",
    "\n",
    "  return loss\n",
    "\n",
    "#print(ce_loss(np.array([.1, .1, .8]), np.array([2])))\n",
    "print(ce_loss(preds, Y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BaRg8b1F93w9"
   },
   "source": [
    "## Computing the Gradient\n",
    "\n",
    "Again, it will turn out that the gradient computation is the same as it was for MSE with linear regression. A happy coincidence.\n",
    "\n",
    "\\begin{align}\n",
    "\\nabla J(W) &= \\frac{1}{m}(h_W(X) - Y)^TX\n",
    "\\end{align}\n",
    "\n",
    "Remember that our parameters $W$ are represented by a matrix of shape (3 x 4): 3 classes and 4 features. The gradient will include a partial derivative for every parameter, and is an average over gradients computed on each training example.\n",
    "\n",
    "Let's review the matrix shapes:\n",
    "\n",
    "* $h_W(X)$ is (100 x 3): 3 probabilities for each example.\n",
    "* $Y$ is (100 x 3): this is the dense (one-hot) version of the labels, matching the shape of the predictions.\n",
    "* $X$ is (100 x 4): 4 features for each example.\n",
    "* The resulting product is (3 x 100)(100 x 4), giving a (3 x 4) output, which matches the shape of our parameters $W$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "0-j0soKK2qfc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradient:\n",
      " [[ 0.337 -0.28   0.431  0.411]\n",
      " [-0.042  0.191 -0.089 -0.046]\n",
      " [-0.295  0.09  -0.342 -0.365]]\n"
     ]
    }
   ],
   "source": [
    "# y' = [.1, .2, .7]  y = [0, 0, 1]  diff = y' - y = [.1, .2, -.3]\n",
    "# d1 = [.1, .2, -.3]  x1 = [1, 2, 3, 4]\n",
    "# (3 x 100) (100 x 4) -> (3 x 4)\n",
    "# [ [ .1*1,  .1*2,  .1*3,  .1*4 ]\n",
    "#   [ .2*1,  .2*2,  .2*3,  .2*4 ]\n",
    "#   [-.3*1, -.3*2, -.3*3, -.3*4 ]\n",
    "# ]\n",
    "#\n",
    "# We need the dense version of Y here\n",
    "m = Y_train.shape[0]\n",
    "Y_train_dense = tf.keras.utils.to_categorical(Y_train)\n",
    "diff = preds - Y_train_dense\n",
    "gradient = np.dot(diff.T, X_train) / m\n",
    "print('gradient:\\n', gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ExL4G-pMAXvV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.333]\n",
      " [ 0.333]\n",
      " [-0.667]]\n",
      "[[-0.017 -0.543  0.76   1.567]]\n",
      "gradient:\n",
      " [[-0.006 -0.181  0.253  0.522]\n",
      " [-0.006 -0.181  0.253  0.522]\n",
      " [ 0.011  0.362 -0.507 -1.045]]\n"
     ]
    }
   ],
   "source": [
    "# Simplify and just compute the gradient for the first training example.\n",
    "print(diff[0:1].T)\n",
    "print(X_train[0:1])\n",
    "print('gradient:\\n', np.dot(diff[0:1].T, X_train[0:1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VZDyrbc42rcF"
   },
   "source": [
    "## Running Gradient Descent\n",
    "\n",
    "Let's put together the code for a single gradient descent step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Zl_Nu_wB8ar4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels:\n",
      " [2 1 0 2 0 2]\n",
      "predictions:\n",
      " [[0.025 0.201 0.774]\n",
      " [0.084 0.673 0.243]\n",
      " [0.99  0.006 0.003]\n",
      " [0.007 0.154 0.838]\n",
      " [0.962 0.032 0.006]\n",
      " [0.014 0.081 0.905]]\n",
      "loss: 0.43657251861677077\n",
      "gradient:\n",
      " [[ 0.012 -0.026  0.026  0.023]\n",
      " [-0.01   0.026 -0.007  0.01 ]\n",
      " [-0.001 -0.    -0.018 -0.033]]\n",
      "weights:\n",
      " [[0.539 1.556 0.295 0.347]\n",
      " [1.08  0.492 1.132 0.922]\n",
      " [1.381 0.951 1.573 1.731]]\n"
     ]
    }
   ],
   "source": [
    "# Run gradient descent\n",
    "m, n = X.shape  # m = number of examples; n = number of features (including bias)\n",
    "learning_rate = 0.01\n",
    "\n",
    "for _ in range(1000):\n",
    "  preds = softmax(np.dot(X_train, W.T))\n",
    "  loss = ce_loss(preds, Y_train)\n",
    "  gradient = np.dot((preds - tf.keras.utils.to_categorical(Y_train)).T, X_train) / m\n",
    "  W = W - learning_rate * gradient\n",
    "\n",
    "print('labels:\\n', Y_train[:6])\n",
    "print('predictions:\\n', preds[:6])\n",
    "print('loss:', loss)\n",
    "print('gradient:\\n', gradient)\n",
    "print('weights:\\n', W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8q72Tu_n_LlO"
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "tj3z7t6-_PZ4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.84\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test data\n",
    "test_preds = softmax(np.dot(X_test, W.T))\n",
    "test_pred_labels = np.argmax(test_preds, axis=1)\n",
    "print('Accuracy:', np.mean(test_pred_labels == Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "xcq8zqKDALmC"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cf = tf.math.confusion_matrix(Y_test, test_pred_labels)\n",
    "ax = sns.heatmap(cf, annot=True, fmt='.3g', cmap='Blues',\n",
    "                 xticklabels=class_names, yticklabels=class_names, cbar=False)\n",
    "ax.set(xlabel='Predicted Label', ylabel='True Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BMsSJ-ZD_12e"
   },
   "source": [
    "## Now with TensorFlow/Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "jisaFtGY__KL"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jcisneros/.local/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(\n",
    "    units=3,                     # output dim\n",
    "    input_shape=[4],             # input dim\n",
    "    use_bias=False,              # we included the bias in X\n",
    "    activation='softmax',        # apply a sigmoid to the output\n",
    "    kernel_initializer=tf.ones_initializer,  # initialize params to 1\n",
    "))\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "3PQ-RDwXCKVt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step  \n",
      "predictions:\n",
      " [[0.333 0.333 0.333]\n",
      " [0.333 0.333 0.333]\n",
      " [0.333 0.333 0.333]\n",
      " [0.333 0.333 0.333]\n",
      " [0.333 0.333 0.333]\n",
      " [0.333 0.333 0.333]]\n",
      "loss: 0.9882702827453613\n",
      "W:\n",
      " [[ 0.271  2.929 -0.805 -0.724]\n",
      " [ 1.631 -0.267  2.123  0.143]\n",
      " [ 1.218  0.65   2.025  2.944]]\n"
     ]
    }
   ],
   "source": [
    "# As above, get predictions for the current model first.\n",
    "preds = model.predict(X)\n",
    "\n",
    "# Do a single gradient update.\n",
    "history = model.fit(\n",
    "  x = X_train,\n",
    "  y = Y_train,\n",
    "  epochs=100,\n",
    "  batch_size=10,\n",
    "  verbose=0)\n",
    "\n",
    "# Show the loss (before the update) and the new weights.\n",
    "loss = history.history['loss'][0]\n",
    "weights = model.layers[0].get_weights()[0].T\n",
    "print('predictions:\\n', preds[:6])\n",
    "print('loss:', loss)\n",
    "print('W:\\n', weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "QAmb6PMCTVET"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9882702827453613, 0.7957561612129211, 0.6787416934967041, 0.6009948253631592, 0.5493622422218323, 0.5165287852287292, 0.4933890402317047, 0.47669246792793274, 0.4622238576412201, 0.4516788423061371, 0.44298556447029114, 0.4347713589668274, 0.4282585084438324, 0.42186909914016724, 0.4167783856391907, 0.4121841788291931, 0.4083157479763031, 0.4040706753730774, 0.3998919725418091, 0.39706677198410034, 0.39352667331695557, 0.390574187040329, 0.38786107301712036, 0.3856927454471588, 0.38363683223724365, 0.3812272548675537, 0.3790571987628937, 0.37720370292663574, 0.37556228041648865, 0.3733408749103546, 0.37188392877578735, 0.370085746049881, 0.3689166009426117, 0.3676031529903412, 0.36676180362701416, 0.36501696705818176, 0.3637312948703766, 0.36304569244384766, 0.3616339862346649, 0.36063361167907715, 0.3595139980316162, 0.35886943340301514, 0.35797786712646484, 0.3577648401260376, 0.3563980162143707, 0.3554759621620178, 0.3551570773124695, 0.353912889957428, 0.3535621166229248, 0.3527664542198181, 0.35233426094055176, 0.35223329067230225, 0.3511657416820526, 0.35038644075393677, 0.34971553087234497, 0.3493961691856384, 0.34850043058395386, 0.34934863448143005, 0.347732275724411, 0.3472626507282257, 0.3468743562698364, 0.3462759852409363, 0.3460736572742462, 0.3460037112236023, 0.34594154357910156, 0.34474390745162964, 0.34459301829338074, 0.3444710671901703, 0.3439202606678009, 0.343661904335022, 0.3430892825126648, 0.34254226088523865, 0.3424607515335083, 0.3420570492744446, 0.3421857953071594, 0.34141045808792114, 0.3421241044998169, 0.34113430976867676, 0.34058111906051636, 0.3406153917312622, 0.3405591547489166, 0.34017300605773926, 0.33983132243156433, 0.3396497368812561, 0.3388877809047699, 0.3386248052120209, 0.3384381830692291, 0.33833929896354675, 0.3383139371871948, 0.3379591703414917, 0.3385051488876343, 0.33809134364128113, 0.33772990107536316, 0.3370937407016754, 0.3371540904045105, 0.33657553791999817, 0.3365107476711273, 0.3364855945110321, 0.3359139561653137, 0.3361492455005646]\n"
     ]
    }
   ],
   "source": [
    "print(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "DuKK7l4fTktl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "0.9\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2300 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.25451064109802246"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds = model.predict(X_test)\n",
    "test_preds_labels = np.argmax(test_preds, axis=1)\n",
    "accuracy = np.mean(test_preds_labels == Y_test)\n",
    "print(accuracy)\n",
    "model.evaluate(x=X_test, y=Y_test)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOF/SzfGqGLnE58b8QnQuUU",
   "name": "03 Multiclass Logistic Regression.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
